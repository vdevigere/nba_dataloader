{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f2e67a",
   "metadata": {},
   "source": [
    "# Using nba-dataloader\n",
    "\n",
    "This notebook takes you through a few examples of downloading data from http://stats.nba.com and using it to do some simple data analysis.\n",
    "\n",
    "## Installation\n",
    "Make sure you have installed the nba-dataloader package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nba-dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00448c",
   "metadata": {},
   "source": [
    "### Make sure package is installed correctly\n",
    "However before we do that let's check out how to use the module using the --help option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m nba_dataloader -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00981baf",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "Lets download some data, for this exercise we will be querying the following resources \n",
    "- [LeagueDashPlayerStats](https://any-api.com/nba_com/nba_com/docs/_leaguedashplayerstats/GET)\n",
    "- [DraftHistory](https://any-api.com/nba_com/nba_com/docs/_drafthistory/GET)\n",
    "\n",
    "You can see the nba_dataloader package requires one parameter ```resource```. Examining [LeagueDashPlayerStats](https://any-api.com/nba_com/nba_com/docs/_leaguedashplayerstats/GET) resource we see that the resource takes a few required request parameters. \n",
    "\n",
    "### Specifying parameters\n",
    "There are a few ways to specify the request parameters:-\n",
    "#### Using --params\n",
    "You can provide a python module containing a variable params of type list of dicts.\n",
    "#### Using Defaults\n",
    "If no parameters are provided, the default behavior of the script is to look for a module called ```request_params.<resource>_params```. \n",
    "    \n",
    "In this case if we used the default, then the script will try to load the request parameters from ```request_params.leaguedashplayerstats_params```\n",
    "\n",
    "If you started the jupyter server in the git repo that you cloned, you will find the module under ```request_params/leaguedashplayerstats.py``` Have a look at the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d523e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "        \"LastNGames\": 0,\n",
    "        \"LeagueID\": \"00\",\n",
    "        \"MeasureType\": \"Base\",\n",
    "        \"Month\": 0,\n",
    "        \"OpponentTeamID\": 0,\n",
    "        \"PORound\": 0,\n",
    "        \"PaceAdjust\": \"N\",\n",
    "        \"PerMode\": \"Totals\",\n",
    "        \"Period\": 0,\n",
    "        \"PlusMinus\": \"N\",\n",
    "        \"Rank\": \"N\",\n",
    "        \"SeasonType\": \"Regular Season\",\n",
    "        \"TeamID\": 0\n",
    "}\n",
    "seasons = {'1996-97', '1997-98', '1998-99', '1999-00', '2000-01', '2001-02', '2002-03', '2003-04', '2004-05',\n",
    "           '2005-06', '2006-07', '2007-08', '2008-09', '2009-10', '2010-11', '2011-12', '2012-13', '2013-14',\n",
    "           '2014-15', '2015-16', '2016-17', '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23'}\n",
    "params = map(lambda season: {'Season': season} | default_params, seasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e0bbb",
   "metadata": {},
   "source": [
    "The ```map(...)``` operation generates a list of dicts generated by appending the key/value \"Season\":<season> to the default_params for each of the 27 seasons from 1996-97 to 2022-23. The result can bee seen by running the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103af64",
   "metadata": {},
   "source": [
    "### Download LeagueDashPlayerstats\n",
    "Let's run the package using the defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e783ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -m nba_dataloader leaguedashplayerstats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d68bde",
   "metadata": {},
   "source": [
    "What just happened??? \n",
    "\n",
    "The script queried the endpoint http://stats.nba.com/leaguedashplayerstats 27 times, once each for every dict value in the ```params``` list. Player stats for every season from 1996-97 to 2022-23 was fetched and the results are stored in ```tmp/LeagueDashPlayerStats``` as a delta table. \n",
    "\n",
    "### Examine delta table\n",
    "Let's examine the contents of the delta table using the delta-rs package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac186daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dt = DeltaTable(\"tmp/leaguedashplayerstats\")\n",
    "display(dt.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fada40e",
   "metadata": {},
   "source": [
    "You will see at total of 12846 players logged minutes from 1996-97 to 2022-23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a5b02",
   "metadata": {},
   "source": [
    "## Querying using Spark\n",
    "Let's see how many players played for each team during this period. This time we will use spark to query the delta tables. \n",
    "\n",
    "### Installing delta-spark\n",
    "However before that we need to install a few more python packages:- pyspark and delta-spark. Ensure you have the compatible versions of the two from [here](https://docs.delta.io/latest/releases.html). We will be installing \n",
    " - [delta-spark==2.4.0](https://pypi.org/project/delta-spark/2.4.0/)\n",
    " - [pyspark==3.4.1](https://pypi.org/project/pyspark/3.4.1/)\n",
    " \n",
    " Installing delta-spark should also install the correct version of pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2049dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install delta-spark==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0a778",
   "metadata": {},
   "source": [
    "### List number of players who have played for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bab79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyspark\n",
    "from delta.pip_utils import configure_spark_with_delta_pip\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "    \n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"NBA Analytics\")\\\n",
    ".config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\\\n",
    ".config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    \n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "df = spark.read.format(\"delta\").load(\"tmp/LeagueDashPlayerStats\")\n",
    "df.createOrReplaceTempView(\"PLAYER_STATS\")\n",
    "spark.sql(\"SELECT TEAM_ABBREVIATION, count(TEAM_ABBREVIATION) as NUM_PLAYERS from PLAYER_STATS\"\\\n",
    "          \" group by TEAM_ABBREVIATION order by NUM_PLAYERS\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a989e",
   "metadata": {},
   "source": [
    "### Download DraftHistory\n",
    "Let us query another resource: [DraftHistory](https://any-api.com/nba_com/nba_com/docs/_drafthistory/GET). This time we will use a custom python module to pass the parameters.\n",
    "\n",
    "Run the cell below to create a python file ```drafthistory_params.py``` with the following content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bc77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile drafthistory_params.py\n",
    "\n",
    "params = [{\n",
    "    \"LeagueID\":\"00\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113a79f",
   "metadata": {},
   "source": [
    "Now run the package to fetch the draft history data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2df77d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -m nba_dataloader drafthistory --params drafthistory_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacc0d9",
   "metadata": {},
   "source": [
    "You can see a total of 8257 players have been drafted into the NBA as of the 2023-24 season. \n",
    "\n",
    "### List of all the number #1 draft picks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6593287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drafthistory = spark.read.format(\"delta\").load(\"tmp/DraftHistory\")\n",
    "drafthistory.createOrReplaceTempView(\"DRAFT_HISTORY\")\n",
    "spark.sql(\"SELECT PLAYER_NAME, SEASON, ROUND_NUMBER, ROUND_PICK from DRAFT_HISTORY\"\\\n",
    "          \" where ROUND_NUMBER=1 and ROUND_PICK=1\").show(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d3432",
   "metadata": {},
   "source": [
    "### All Players drafted by the San Antonio Spurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * from DRAFT_HISTORY where TEAM_ID=1610612759\")\n",
    "df.show(n=df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e536c10",
   "metadata": {},
   "source": [
    "### Spurs players count by draft organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0de40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"WITH SPURS_PICS as ( \"\\\n",
    "         \"SELECT * from DRAFT_HISTORY where TEAM_ID=1610612759)\"\n",
    "         \" SELECT ORGANIZATION, COUNT(ORGANIZATION) as org_count FROM SPURS_PICS GROUP BY ORGANIZATION order by org_count desc\")\n",
    "df.show(n=df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18326bc",
   "metadata": {},
   "source": [
    "### Using Spark-SQL\n",
    "You can also use spark-sql command line tool to query that tables. If you have spark installed you would use the following command.\n",
    "```\n",
    "spark-sql --packages io.delta:delta-core_2.12:2.4.0 --conf \"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension\" --conf \"spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
    "```\n",
    "\n",
    "Remember though that while running queries, you should provide the full table path and not relative while referring to the tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-notebook-kernel",
   "language": "python",
   "name": "nba-notebook-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
